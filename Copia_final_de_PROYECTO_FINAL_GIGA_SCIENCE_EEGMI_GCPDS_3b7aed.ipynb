{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 5175158,
          "sourceType": "datasetVersion",
          "datasetId": 3008205
        }
      ],
      "dockerImageVersionId": 30839,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Richardesl10/Se-alesysistemasrichard/blob/main/Copia_final_de_PROYECTO_FINAL_GIGA_SCIENCE_EEGMI_GCPDS_3b7aed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "dggarciam94_giga_science_gcpds_path = kagglehub.dataset_download('dggarciam94/giga-science-gcpds')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "IWfyesc3bKkr"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto Final Señales y Sistemas 2024 -2\n",
        "\n",
        "## **Objetivo**: Implementar técnicas de representación en tiempo y frecuencia para el reconocimiento de señales de electroencefalografía (EEG) en tareas de imaginación motora (Motor Imagery)\n",
        "\n",
        "![sensorimotora](https://nepsa.es/wp-content/uploads/2021/10/Lengua-Mandibula-Labios-Cara-Ojo-Frente-Cuello-Pulgar-Dedos-Mano-Muneca-Codo-Brazo-Hombro-Maletero-Cadera-3.png)\n",
        "\n",
        "![eegMI](https://figures.semanticscholar.org/288a54f091264377eccc99a19079c9387d66a78f/3-Figure2-1.png)\n",
        "\n",
        "EEG signals can be noisy from a number of sources, including physiological artifacts and electromagnetic interference. They can also vary from person to person, which makes it harder to extract features and understand the signals. Additionally, this variability, influenced by genetic and cognitive factors, presents challenges for developing subject-independent solutions.\n",
        "\n",
        "**Base de datos**: GiGaScience Database [https://gigadb.org/dataset/100295](https://gigadb.org/dataset/100295)\n",
        "\n",
        "Ver Sección 3.1 en [Multimodal Explainability Using Class Activation Maps and Canonical Correlation for MI-EEG Deep Learning Classification](https://www.mdpi.com/2076-3417/14/23/11208)\n"
      ],
      "metadata": {
        "id": "i9dgZVC0bKkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalamos las librerias necesarias\n",
        "\n",
        "## Ejercicio 1\n",
        "Consultar para qué sirven las siguientes librerías"
      ],
      "metadata": {
        "id": "rJAG0TccbKkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 1\n",
        "\n",
        "1. TensorFlow (tensorflow==2.15.0)\n",
        "\n",
        "TensorFlow es una de las bibliotecas más populares para aprendizaje profundo (Deep Learning). Fue desarrollada por Google y se usa en múltiples aplicaciones, como visión por computadora, procesamiento de lenguaje natural y análisis de datos biomédicos, incluyendo EEG.\n",
        "\n",
        "En el contexto del análisis de EEG, TensorFlow se usa para:\n",
        "\n",
        "* Construir y entrenar redes neuronales convolucionales (CNN) y redes recurrentes (RNN) para la clasificación de señales EEG.\n",
        "* Implementar modelos de aprendizaje supervisado y no supervisado para detectar patrones en los datos.\n",
        "* Usar técnicas de interpretabilidad como Class Activation Maps (CAMs) para visualizar qué características de las señales EEG son más relevantes para la clasificación.\n",
        "\n",
        "2. MNE (mne==1.6.0)\n",
        "\n",
        "MNE-Python es una biblioteca especializada en el análisis de señales neurofisiológicas, especialmente EEG y MEG (magnetoencefalografía).\n",
        "\n",
        "Sus principales funcionalidades incluyen:\n",
        "\n",
        "* Carga de datos EEG desde formatos estándar (e.g., EDF, BrainVision, BDF).\n",
        "* Preprocesamiento de señales EEG, como:\n",
        "* Filtrado (pasabanda, notch).\n",
        "* Eliminación de artefactos fisiológicos (como movimientos oculares).\n",
        "* Re-referenciación y normalización.\n",
        "* Análisis en el dominio del tiempo, frecuencia y espacio, permitiendo detectar actividad cerebral en diferentes bandas de frecuencia (theta, alpha, beta, gamma).\n",
        "* Creación de mapas topográficos para visualizar la actividad cerebral en diferentes electrodos.\n",
        "* Análisis de potenciales evocados (ERP) y conectividad cerebral.\n",
        "* MNE es fundamental en el análisis de EEG, ya que proporciona herramientas para procesar señales en bruto antes de usarlas en modelos de  Machine Learning con TensorFlow o Braindecode.\n",
        "\n",
        "3. Braindecode (braindecode==0.7)\n",
        "\n",
        "Braindecode es una biblioteca basada en PyTorch diseñada para el análisis de EEG utilizando aprendizaje profundo. Fue desarrollada específicamente para clasificación de señales EEG en aplicaciones como Brain-Computer Interfaces (BCI).\n",
        "\n",
        "Algunas características clave de Braindecode:\n",
        "\n",
        "* Incluye modelos preentrenados para EEG, como EEGNet y ShallowConvNet.\n",
        "* Permite entrenar redes neuronales profundas (CNNs y RNNs) en conjuntos de datos EEG.\n",
        "* Es compatible con MNE, lo que permite integrar datos preprocesados con modelos de aprendizaje profundo.\n",
        "* Se usa en tareas como clasificación de imágenes motoras (motor imagery) o detección de eventos en EEG clínico.\n",
        "* Braindecode puede servir para experimentar con modelos de Deep Learning aplicados a EEG y probar diferentes arquitecturas para mejorar la clasificación de señales cerebrales.\n",
        "\n",
        "4. GCPDS Databases\n",
        "   \n",
        "Esta es una librería desarrollada por el Grupo de Procesamiento de Señales y Datos (GCPDS) de la Universidad de Navarra. Su objetivo es facilitar el acceso a bases de datos de señales fisiológicas, incluyendo EEG.\n",
        "\n",
        "Sus usos incluyen:\n",
        "\n",
        "* Carga automática de datasets EEG de investigaciones previas.\n",
        "* Integración con modelos de Machine Learning para pruebas y entrenamiento.\n",
        "* Uso en experimentos de Brain-Computer Interfaces (BCI).\n",
        "* Esta librería puede ser útil si deseas trabajar con bases de datos EEG previamente curadas y listas para el análisis sin necesidad de preprocesarlas manualmente."
      ],
      "metadata": {
        "id": "bnwuskn-bKky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow==2.15.0\n",
        "!pip install mne==1.6.0\n",
        "!pip install braindecode===0.7\n",
        "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases"
      ],
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:22.513334Z",
          "iopub.execute_input": "2025-03-07T00:21:22.513722Z",
          "iopub.status.idle": "2025-03-07T00:21:37.788568Z",
          "shell.execute_reply.started": "2025-03-07T00:21:22.513692Z",
          "shell.execute_reply": "2025-03-07T00:21:37.78724Z"
        },
        "id": "zLpIjTKDbKkz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importamos algunas librerias necesarias"
      ],
      "metadata": {
        "id": "S93DMUVBbKkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import resample\n",
        "from scipy.signal import freqz, filtfilt, resample\n",
        "from scipy.signal import butter as bw\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow as tf\n",
        "from gcpds.databases import GIGA_MI_ME\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:37.79063Z",
          "iopub.execute_input": "2025-03-07T00:21:37.790961Z",
          "iopub.status.idle": "2025-03-07T00:21:37.797179Z",
          "shell.execute_reply.started": "2025-03-07T00:21:37.790935Z",
          "shell.execute_reply": "2025-03-07T00:21:37.795912Z"
        },
        "id": "UhZszBfGbKkz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones necesarias para el preprocesamiento leve de los datos"
      ],
      "metadata": {
        "id": "_CDkzRnnbKk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_GIGA(db,\n",
        "              sbj,\n",
        "              eeg_ch_names,\n",
        "              new_fs,\n",
        "              fs,\n",
        "              f_bank=None,\n",
        "              vwt=None,\n",
        "              run=None):\n",
        "\n",
        "    index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n",
        "\n",
        "    #tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n",
        "\n",
        "    db.load_subject(sbj)\n",
        "    if run == None:\n",
        "        X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n",
        "    else:\n",
        "        X, y = db.get_run(run, classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n",
        "    X = X[:, index_eeg_chs, :] #spatial rearrangement\n",
        "    #X = np.squeeze(tf_repr.transform(X))\n",
        "    #Resampling\n",
        "    if new_fs == fs:\n",
        "        pass#print('No resampling, since new sampling rate same.')\n",
        "    else:\n",
        "        print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n",
        "        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def butterworth_digital_filter(X, N, Wn, btype, fs, axis=-1, padtype=None, padlen=0, method='pad', irlen=None):\n",
        "  \"\"\"\n",
        "  Apply digital butterworth filter\n",
        "  INPUT\n",
        "  ------\n",
        "  1. X: (D array)\n",
        "    array with signals.\n",
        "  2. N: (int+)\n",
        "    The order of the filter.\n",
        "  3. Wn: (float+ or 1D array)\n",
        "    The critical frequency or frequencies. For lowpass and highpass filters, Wn is a scalar; for bandpass and bandstop filters, Wn is a length-2 vector.\n",
        "    For a Butterworth filter, this is the point at which the gain drops to 1/sqrt(2) that of the passband (the “-3 dB point”).\n",
        "    If fs is not specified, Wn units are normalized from 0 to 1, where 1 is the Nyquist frequency (Wn is thus in half cycles / sample and defined as 2*critical frequencies / fs). If fs is specified, Wn is in the same units as fs.\n",
        "  4. btype: (str) {‘lowpass’, ‘highpass’, ‘bandpass’, ‘bandstop’}\n",
        "    The type of filter\n",
        "  5. fs: (float+)\n",
        "    The sampling frequency of the digital system.\n",
        "  6. axis: (int), Default=1.\n",
        "    The axis of x to which the filter is applied.\n",
        "  7. padtype: (str) or None, {'odd', 'even', 'constant'}\n",
        "    This determines the type of extension to use for the padded signal to which the filter is applied. If padtype is None, no padding is used. The default is ‘odd’.\n",
        "  8. padlen: (int+) or None, Default=0\n",
        "    The number of elements by which to extend x at both ends of axis before applying the filter. This value must be less than x.shape[axis] - 1. padlen=0 implies no padding.\n",
        "  9. method: (str), {'pad', 'gust'}\n",
        "    Determines the method for handling the edges of the signal, either “pad” or “gust”. When method is “pad”, the signal is padded; the type of padding is determined by padtype\n",
        "    and padlen, and irlen is ignored. When method is “gust”, Gustafsson’s method is used, and padtype and padlen are ignored.\n",
        "  10. irlen: (int) or None, Default=nONE\n",
        "    When method is “gust”, irlen specifies the length of the impulse response of the filter. If irlen is None, no part of the impulse response is ignored.\n",
        "    For a long signal, specifying irlen can significantly improve the performance of the filter.\n",
        "  OUTPUT\n",
        "  ------\n",
        "  X_fil: (D array)\n",
        "    array with filtered signals.\n",
        "  \"\"\"\n",
        "  b, a = bw(N, Wn, btype, analog=False, output='ba', fs=fs)\n",
        "  return filtfilt(b, a, X, axis=axis, padtype=padtype, padlen=padlen, method=method, irlen=irlen)\n",
        "\n",
        "class TimeFrequencyRpr(BaseEstimator, TransformerMixin):\n",
        "  \"\"\"\n",
        "  Time frequency representation of EEG signals.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "    1. sfreq:  (float) Sampling frequency in Hz.\n",
        "    2. f_bank: (2D array) Filter banks Frequencies. Default=None\n",
        "    3. vwt:    (2D array) Interest time windows. Default=None\n",
        "  Methods\n",
        "  -------\n",
        "    1. fit(X, y=None)\n",
        "    2. transform(X, y=None)\n",
        "  \"\"\"\n",
        "  def __init__(self, sfreq, f_bank=None, vwt=None):\n",
        "    self.sfreq = sfreq\n",
        "    self.f_bank = f_bank\n",
        "    self.vwt = vwt\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "  def _validation_param(self):\n",
        "    \"\"\"\n",
        "    Validate Time-Frequency characterization parameters.\n",
        "    INPUT\n",
        "    -----\n",
        "      1. self\n",
        "    ------\n",
        "      2. None\n",
        "    \"\"\"\n",
        "    if self.sfreq <= 0:\n",
        "      raise ValueError('Non negative sampling frequency is accepted')\n",
        "\n",
        "\n",
        "    if self.f_bank is None:\n",
        "      self.flag_f_bank = False\n",
        "    elif self.f_bank.ndim != 2:\n",
        "      raise ValueError('Band frequencies have to be a 2D array')\n",
        "    else:\n",
        "      self.flag_f_bank = True\n",
        "\n",
        "    if self.vwt is None:\n",
        "      self.flag_vwt = False\n",
        "    elif self.vwt.ndim != 2:\n",
        "      raise ValueError('Time windows have to be a 2D array')\n",
        "    else:\n",
        "      self.flag_vwt = True\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "  def _filter_bank(self, X):\n",
        "    \"\"\"\n",
        "    Filter bank Characterization.\n",
        "    INPUT\n",
        "    -----\n",
        "      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
        "    OUTPUT\n",
        "    ------\n",
        "      1. X_f: (4D array) set of filtered EEG signals, shape (trials, channels, time_samples, frequency_bands)\n",
        "    \"\"\"\n",
        "    X_f = np.zeros((X.shape[0], X.shape[1], X.shape[2], self.f_bank.shape[0])) #epochs, Ch, Time, bands\n",
        "    for f in np.arange(self.f_bank.shape[0]):\n",
        "      X_f[:,:,:,f] = butterworth_digital_filter(X, N=5, Wn=self.f_bank[f], btype='bandpass', fs=self.sfreq)\n",
        "    return X_f\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "  def _sliding_windows(self, X):\n",
        "    \"\"\"\n",
        "    Sliding Windows Characterization.\n",
        "    INPUT\n",
        "    -----\n",
        "      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
        "    OUTPUT\n",
        "    ------\n",
        "      1. X_w: (4D array) shape (trials, channels, window_time_samples, number_of_windows)\n",
        "    \"\"\"\n",
        "    window_lenght = int(self.sfreq*self.vwt[0,1] - self.sfreq*self.vwt[0,0])\n",
        "    X_w = np.zeros((X.shape[0], X.shape[1], window_lenght, self.vwt.shape[0]))\n",
        "    for w in np.arange(self.vwt.shape[0]):\n",
        "        X_w[:,:,:,w] = X[:,:,int(self.sfreq*self.vwt[w,0]):int(self.sfreq*self.vwt[w,1])]\n",
        "    return X_w\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "  def fit(self, X, y=None):\n",
        "    \"\"\"\n",
        "    fit.\n",
        "    INPUT\n",
        "    -----\n",
        "      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
        "      2. y: (1D array) target labels. Default=None\n",
        "    OUTPUT\n",
        "    ------\n",
        "      1. None\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "  def transform(self, X, y=None):\n",
        "    \"\"\"\n",
        "    Time frequency representation of EEG signals.\n",
        "    INPUT\n",
        "    -----\n",
        "      1. X: (3D array) set of EEG signals, shape (trials, channels, times)\n",
        "    OUTPUT\n",
        "    ------\n",
        "      1. X_wf: (5D array) Time-frequency representation of EEG signals, shape (trials, channels, window_time_samples, number_of_windows, frequency_bands)\n",
        "    \"\"\"\n",
        "    self._validation_param()     #Validate sfreq, f_freq, vwt\n",
        "\n",
        "    #Avoid edge effects of digital filter, 1st:fbk, 2th:vwt\n",
        "    if self.flag_f_bank:\n",
        "        X_f = self._filter_bank(X)\n",
        "    else:\n",
        "        X_f = X[:,:,:,np.newaxis]\n",
        "\n",
        "    if self.flag_vwt:\n",
        "      X_wf = []\n",
        "      for f in range(X_f.shape[3]):\n",
        "        X_wf.append(self._sliding_windows(X_f[:,:,:,f]))\n",
        "      X_wf = np.stack(X_wf, axis=-1)\n",
        "    else:\n",
        "      X_wf = X_f[:,:,:,np.newaxis,:]\n",
        "\n",
        "    return X_wf\n",
        "\n",
        "#plot eeg\n",
        "def plot_eeg(X,tv,ax,channels,esp=2,title=None):\n",
        "    # X in CH x Samples\n",
        "    n_canales = X.shape[0]\n",
        "\n",
        "    for ch in range(n_canales): # canales\n",
        "            xx = X[ch]\n",
        "            xx = xx - np.mean(xx)\n",
        "            xx = xx/np.max(abs(xx))\n",
        "            ax.plot(tv, xx +(ch * esp), label=channels[ch])  # Desplazamos cada canal para visualización\n",
        "    ax.set_yticks(range(0, esp * n_canales, esp), channels)  # Etiquetas en el eje Y\n",
        "    ax.set_xlabel(\"Tiempo [s]\")\n",
        "    ax.set_ylabel(\"Canales EEG [$\\mu$V]\")\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True)\n",
        "    ax.set_xlim([min(tv)-0.01,max(tv)+0.01])\n",
        "    ax.set_ylim([-esp,n_canales*esp+0.01])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:37.799006Z",
          "iopub.execute_input": "2025-03-07T00:21:37.799244Z",
          "iopub.status.idle": "2025-03-07T00:21:37.824923Z",
          "shell.execute_reply.started": "2025-03-07T00:21:37.799217Z",
          "shell.execute_reply": "2025-03-07T00:21:37.823273Z"
        },
        "id": "Oy9rcXvKbKk0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Establecemos el protocolo de pruebas y la configuración del montaje EEG\n",
        "\n",
        "Describir el protocolo de captura de datos y el montaje utilizado\n",
        "\n",
        "\n",
        "![mi](https://www.mdpi.com/diagnostics/diagnostics-13-01122/article_deploy/html/images/diagnostics-13-01122-g001.png)\n",
        "![montaje](https://www.mdpi.com/applsci/applsci-14-11208/article_deploy/html/images/applsci-14-11208-g001.png)"
      ],
      "metadata": {
        "id": "H3fgKx6WbKk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###solucion"
      ],
      "metadata": {
        "id": "-Q-EjKZXbKk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Protocolo de Captura de Datos\n",
        "\n",
        "Preparación del sujeto:\n",
        "El sujeto se sienta en una silla cómoda con electrodos colocados en su cuero cabelludo, siguiendo el sistema de colocación 10-20.\n",
        "\n",
        "Se establecen las conexiones con un sistema de adquisición de EEG (electroencefalografía).\n",
        "\n",
        "1.1  Presentación de estímulos:\n",
        "Una pantalla frente al sujeto presenta señales visuales (visual cue) indicando la tarea mental a realizar.\n",
        "\n",
        "Las instrucciones pueden indicar la imaginación del movimiento de la mano izquierda o derecha.\n",
        "\n",
        "1.2. Registro del EEG:\n",
        "Durante el periodo indicado (por ejemplo, 5 segundos), el sujeto realiza la tarea mental de imaginar el movimiento de la mano especificada.\n",
        "\n",
        "Los electrodos capturan la actividad cerebral en áreas motoras relevantes.\n",
        "\n",
        " 1.3. Intervalos entre pruebas:\n",
        "Se incluyen periodos de descanso entre ensayos de aproximadamente 0.1-0.8 segundos.\n",
        "\n",
        "Montaje Utilizado\n",
        "\n",
        "2.1 Electrodos EEG:\n",
        "Colocados en posiciones estratégicas sobre la corteza motora, con énfasis en la región central del cuero cabelludo (C3, Cz, C4).\n",
        "Se destacan en rojo los electrodos más relevantes para la tarea.\n",
        "Dispositivos:\n",
        "Un PC para procesar los datos y presentar estímulos visuales.\n",
        "Una interfaz para la adquisición y procesamiento de las señales EEG.\n"
      ],
      "metadata": {
        "id": "-sD_yDXZbKk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "channels = ['Fp1','Fpz','Fp2',\n",
        "            'AF7','AF3','AFz','AF4','AF8',\n",
        "            'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n",
        "            'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n",
        "            'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n",
        "            'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n",
        "            'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n",
        "            'PO7','PO3','POz','PO4','PO8',\n",
        "            'O1','Oz','O2',\n",
        "            'Iz']\n",
        "\n",
        "areas = {\n",
        "    'Frontal': ['Fpz', 'AFz', 'Fz', 'FCz'],\n",
        "    'Frontal Right': ['Fp2','AF4','AF8','F2','F4','F6','F8',],\n",
        "    'Central Right': ['FC2','FC4','FC6','FT8','C2','C4','C6','T8','CP2','CP4','CP6','TP8',],\n",
        "    'Posterior Right': ['P2','P4','P6','P8','P10','PO4','PO8','O2',],\n",
        "    #'Central': ['Cz'],\n",
        "    'Posterior': ['CPz','Pz', 'Cz','POz','Oz','Iz',],\n",
        "    'Posterior Left': ['P1','P3','P5','P7','P9','PO3','PO7','O1',],\n",
        "    'Central Left': ['FC1','FC3','FC5','FT7','C1','C3','C5','T7','CP1','CP3','CP5','TP7',],\n",
        "    'Frontal Left': ['Fp1','AF3','AF7','F1','F3','F5','F7',],\n",
        "}\n",
        "\n",
        "arcs = [\n",
        "    #'hemispheres',\n",
        "    'areas',\n",
        "    'channels',\n",
        "]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:37.826671Z",
          "iopub.execute_input": "2025-03-07T00:21:37.827011Z",
          "iopub.status.idle": "2025-03-07T00:21:37.842049Z",
          "shell.execute_reply.started": "2025-03-07T00:21:37.826985Z",
          "shell.execute_reply": "2025-03-07T00:21:37.840986Z"
        },
        "id": "N_4Chs6obKk4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definimos la ruta y los argumentos para la carga de los datos de EEG"
      ],
      "metadata": {
        "id": "b4MsdX9ibKk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\n",
        "#ti = 0\n",
        "#tf = 7\n",
        "new_fs = 256.\n",
        "load_args = dict(db = db,\n",
        "                 eeg_ch_names = channels,\n",
        "                 fs = db.metadata['sampling_rate'],\n",
        "                 #f_bank = np.asarray([[4., 40.]]),\n",
        "                 #vwt = np.asarray([[ti, tf]]), #2.5 - 5 MI\n",
        "                 new_fs = new_fs)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:37.843268Z",
          "iopub.execute_input": "2025-03-07T00:21:37.843555Z",
          "iopub.status.idle": "2025-03-07T00:21:37.897774Z",
          "shell.execute_reply.started": "2025-03-07T00:21:37.843528Z",
          "shell.execute_reply": "2025-03-07T00:21:37.896273Z"
        },
        "id": "TlqxBlqIbKk4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargamos los datos según el sujeto que se quiera"
      ],
      "metadata": {
        "id": "a3dQ8tdlbKk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si se quiere cargar los datos de todos los sujetos, aplicar un ciclo que itere la lista de sujetos y de esta forma se cargara uno por uno dependiendo lo que se desee realizar.\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "for i in sbj:\n",
        "    X, y = load_GIGA(sbj=sbj, **load_args)"
      ],
      "metadata": {
        "id": "O4M74OGJbKk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\n",
        "sbj = 35\n",
        "new_fs = 256.\n",
        "load_args = dict(db = db,\n",
        "                 eeg_ch_names = channels,\n",
        "                 fs = db.metadata['sampling_rate'],\n",
        "                 #f_bank = np.asarray([[4., 40.]]),\n",
        "                 #vwt = np.asarray([[ti, tf]]), #2.5 - 5 MI\n",
        "                 new_fs = new_fs)\n",
        "X, y = load_GIGA(sbj=sbj, **load_args)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:37.899157Z",
          "iopub.execute_input": "2025-03-07T00:21:37.899505Z",
          "iopub.status.idle": "2025-03-07T00:21:40.356523Z",
          "shell.execute_reply.started": "2025-03-07T00:21:37.899474Z",
          "shell.execute_reply": "2025-03-07T00:21:40.355198Z"
        },
        "id": "EdrECKkgbKk5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:40.357507Z",
          "iopub.execute_input": "2025-03-07T00:21:40.357847Z",
          "iopub.status.idle": "2025-03-07T00:21:40.364946Z",
          "shell.execute_reply.started": "2025-03-07T00:21:40.357787Z",
          "shell.execute_reply": "2025-03-07T00:21:40.363452Z"
        },
        "id": "wg4-ynbubKk5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X con {X.shape[0]} intentos; {X.shape[1]} canales; {X.shape[2]} muestras No. de segundos {X.shape[2]/new_fs}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:40.368599Z",
          "iopub.execute_input": "2025-03-07T00:21:40.36898Z",
          "iopub.status.idle": "2025-03-07T00:21:40.384356Z",
          "shell.execute_reply.started": "2025-03-07T00:21:40.368951Z",
          "shell.execute_reply": "2025-03-07T00:21:40.382695Z"
        },
        "id": "1fiF9ohBbKk5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:40.386406Z",
          "iopub.execute_input": "2025-03-07T00:21:40.386835Z",
          "iopub.status.idle": "2025-03-07T00:21:40.404834Z",
          "shell.execute_reply.started": "2025-03-07T00:21:40.386782Z",
          "shell.execute_reply": "2025-03-07T00:21:40.403405Z"
        },
        "id": "W8I2zRLkbKk6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Lista de canales relevantes (FC, C y CP)\n",
        "canales_de_interes = [i for i, ch in enumerate(channels) if ch.startswith(('FC', 'C', 'CP'))]\n",
        "\n",
        "# Filtrar X para quedarnos solo con estos canales\n",
        "X_filtrado = X[:, canales_de_interes, :]\n",
        "\n",
        "print(f\"Nuevo shape: {X_filtrado.shape}\")  # (intentos, cantidad de canales seleccionados, muestras)\n",
        "\n",
        "# Promediar sobre intentos\n",
        "X_promedio = np.mean(X_filtrado, axis=0)  # (cantidad de canales seleccionados, muestras)\n",
        "\n",
        "X_promedio.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:40.40592Z",
          "iopub.execute_input": "2025-03-07T00:21:40.406196Z",
          "iopub.status.idle": "2025-03-07T00:21:40.432389Z",
          "shell.execute_reply.started": "2025-03-07T00:21:40.406176Z",
          "shell.execute_reply": "2025-03-07T00:21:40.43094Z"
        },
        "id": "aOP2wA2EbKk6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_promedio.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:40.433346Z",
          "iopub.execute_input": "2025-03-07T00:21:40.433614Z",
          "iopub.status.idle": "2025-03-07T00:21:40.442934Z",
          "shell.execute_reply.started": "2025-03-07T00:21:40.433591Z",
          "shell.execute_reply": "2025-03-07T00:21:40.441856Z"
        },
        "id": "aFjgLkm_bKk7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el rango de tiempo\n",
        "trial = 0  # Intento a graficar (aunque ahora usamos la señal promediada)\n",
        "ti = 0  # Tiempo inicial en segundos\n",
        "tf = X_promedio.shape[1] / new_fs  # Tiempo final en segundos\n",
        "tv = np.arange(ti, tf, 1 / new_fs)  # Vector de tiempo\n",
        "\n",
        "# Crear figura\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 8), sharex=True)\n",
        "\n",
        "# Graficar la señal promediada usando los canales de interés\n",
        "plot_eeg(X_promedio, tv, ax=ax, channels=[channels[i] for i in canales_de_interes], title='EEG Promediado')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:40.443705Z",
          "iopub.execute_input": "2025-03-07T00:21:40.443968Z",
          "iopub.status.idle": "2025-03-07T00:21:41.291637Z",
          "shell.execute_reply.started": "2025-03-07T00:21:40.443941Z",
          "shell.execute_reply": "2025-03-07T00:21:41.290414Z"
        },
        "id": "Lm3I77E-bKk7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sbj = 1\n",
        "X, y = load_GIGA(sbj=sbj, **load_args)\n",
        "\n",
        "# Lista de canales relevantes (FC, C y CP)\n",
        "canales_de_interes = [i for i, ch in enumerate(channels) if ch.startswith(('FC', 'C', 'CP'))]\n",
        "\n",
        "# Filtrar X para quedarnos solo con estos canales\n",
        "X_filtrado = X[:, canales_de_interes, :]\n",
        "\n",
        "print(f\"Nuevo shape: {X_filtrado.shape}\")  # (intentos, cantidad de canales seleccionados, muestras)\n",
        "\n",
        "# Promediar sobre intentos\n",
        "X_promedio = np.mean(X_filtrado, axis=0)  # (cantidad de canales seleccionados, muestras)\n",
        "\n",
        "X_promedio.shape\n",
        "\n",
        "# Definir el rango de tiempo\n",
        "trial = 0  # Intento a graficar (aunque ahora usamos la señal promediada)\n",
        "ti = 0  # Tiempo inicial en segundos\n",
        "tf = X_promedio.shape[1] / new_fs  # Tiempo final en segundos\n",
        "tv = np.arange(ti, tf, 1 / new_fs)  # Vector de tiempo\n",
        "\n",
        "# Crear figura\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 8), sharex=True)\n",
        "\n",
        "# Graficar la señal promediada usando los canales de interés\n",
        "plot_eeg(X_promedio, tv, ax=ax, channels=[channels[i] for i in canales_de_interes], title='EEG Promediado')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:41.29295Z",
          "iopub.execute_input": "2025-03-07T00:21:41.293393Z",
          "iopub.status.idle": "2025-03-07T00:21:43.851956Z",
          "shell.execute_reply.started": "2025-03-07T00:21:41.293371Z",
          "shell.execute_reply": "2025-03-07T00:21:43.851043Z"
        },
        "id": "xp7P78x5bKk7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el rango de tiempo\n",
        "trial = 0  # Intento a graficar (aunque ahora usamos la señal promediada)\n",
        "ti = 0  # Tiempo inicial en segundos\n",
        "tf = X_promedio.shape[1] / new_fs  # Tiempo final en segundos\n",
        "tv = np.arange(ti, tf, 1 / new_fs)  # Vector de tiempo\n",
        "\n",
        "# Crear figura\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 8), sharex=True)\n",
        "\n",
        "# Graficar la señal promediada usando los canales de interés\n",
        "plot_eeg(X_promedio, tv, ax=ax, channels=[channels[i] for i in canales_de_interes], title='EEG Promediado')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:43.852855Z",
          "iopub.execute_input": "2025-03-07T00:21:43.853192Z",
          "iopub.status.idle": "2025-03-07T00:21:44.132256Z",
          "shell.execute_reply.started": "2025-03-07T00:21:43.853157Z",
          "shell.execute_reply": "2025-03-07T00:21:44.131371Z"
        },
        "id": "l9jSEumCbKk7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Variable global para almacenar la información procesada de cada sujeto.\n",
        "# Estructura: { sbj: { 'left': X_left_avg, 'right': X_right_avg, 'time': tv } }\n",
        "global_eeg_promedios = {}\n",
        "\n",
        "# Lista de índices de canales de interés: se filtran los canales que comienzan con \"FC\", \"C\" o \"CP\"\n",
        "canales_de_interes = [i for i, ch in enumerate(channels) if ch.startswith(('FC', 'C', 'CP'))]\n",
        "\n",
        "# Iterar sobre los 52 sujetos\n",
        "for sbj in range(28, 53):\n",
        "\n",
        "    if (29 == sbj or sbj == 34):\n",
        "        pass\n",
        "    else:\n",
        "        print(f\"Procesando sujeto {sbj}...\")\n",
        "\n",
        "        # Cargar datos del sujeto. load_GIGA retorna X (EEG) y y (etiquetas: 0 y 1)\n",
        "        X, y = load_GIGA(sbj=sbj, **load_args)\n",
        "\n",
        "        # Filtrar los canales de interés: X tiene forma (intentos, canales, muestras)\n",
        "        X_filtrado = X[:, canales_de_interes, :]\n",
        "\n",
        "        # Separar ensayos según la mano:\n",
        "        # Se asume: 0 -> mano izquierda y 1 -> mano derecha.\n",
        "        idx_left = (y == 0)\n",
        "        idx_right = (y == 1)\n",
        "\n",
        "        # Verificar que existan ensayos para cada condición\n",
        "        if np.sum(idx_left) == 0:\n",
        "            print(f\"Advertencia: Sujeto {sbj} no tiene ensayos para mano izquierda.\")\n",
        "            continue\n",
        "        if np.sum(idx_right) == 0:\n",
        "            print(f\"Advertencia: Sujeto {sbj} no tiene ensayos para mano derecha.\")\n",
        "            continue\n",
        "\n",
        "        # Extraer y promediar los intentos para cada mano\n",
        "        X_left = X_filtrado[idx_left, :, :]    # Ensayos de mano izquierda, forma: (n_trials_left, canales, muestras)\n",
        "        X_right = X_filtrado[idx_right, :, :]   # Ensayos de mano derecha, forma: (n_trials_right, canales, muestras)\n",
        "\n",
        "        X_left_avg = np.mean(X_left, axis=0)      # (canales, muestras)\n",
        "        X_right_avg = np.mean(X_right, axis=0)    # (canales, muestras)\n",
        "\n",
        "        # Definir el vector de tiempo basado en new_fs\n",
        "        ti = 0\n",
        "        tf_total = X_left_avg.shape[1] / new_fs  # Se asume que ambos tienen el mismo número de muestras\n",
        "        tv = np.arange(ti, tf_total, 1 / new_fs)\n",
        "\n",
        "        # Almacenar los promedios y el vector de tiempo en la variable global\n",
        "        global_eeg_promedios[sbj] = {'left': X_left_avg, 'right': X_right_avg, 'time': tv}\n",
        "\n",
        "        # Crear figura con dos subplots (uno para cada mano)\n",
        "        fig, ax = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
        "\n",
        "        # Graficar mano izquierda (usando únicamente los canales filtrados)\n",
        "        plot_eeg(X_left_avg, tv, ax=ax[0], channels=[channels[i] for i in canales_de_interes],\n",
        "             title=f'EEG Promediado Mano Izquierda - Sujeto {sbj}')\n",
        "\n",
        "        # Graficar mano derecha\n",
        "        plot_eeg(X_right_avg, tv, ax=ax[1], channels=[channels[i] for i in canales_de_interes],\n",
        "             title=f'EEG Promediado Mano Derecha - Sujeto {sbj}')\n",
        "        ax[1].set_xlabel(\"Tiempo [s]\")\n",
        "\n",
        "        # Mostrar la figura en pantalla\n",
        "        plt.show()\n",
        "        plt.close(fig)\n",
        "\n",
        "        print(f\"Mostrado y almacenado sujeto {sbj}\")\n",
        "\n",
        "    print(\"Procesamiento completado para todos los sujetos.\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:21:44.133192Z",
          "iopub.execute_input": "2025-03-07T00:21:44.133436Z",
          "iopub.status.idle": "2025-03-07T00:22:53.189518Z",
          "shell.execute_reply.started": "2025-03-07T00:21:44.133415Z",
          "shell.execute_reply": "2025-03-07T00:22:53.188119Z"
        },
        "id": "sI7KM8IfbKk8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización de las señales de EEG en el tiempo"
      ],
      "metadata": {
        "id": "V8x2ioYhbKk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#graficar canales promedio\n",
        "trial = 0\n",
        "ti = 0 # ti\n",
        "tf = 7 # tf\n",
        "tv = np.arange(ti,tf,1/new_fs)\n",
        "\n",
        "#Señal cruda\n",
        "fig,ax = plt.subplots(1,1,figsize=(8,8),sharex = True)\n",
        "# Graficar cada canal en un subplot banda respectiva\n",
        "\n",
        "plot_eeg(X[trial],tv,ax=ax,channels=channels,title='EEG original')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:22:53.190603Z",
          "iopub.execute_input": "2025-03-07T00:22:53.190928Z",
          "iopub.status.idle": "2025-03-07T00:22:53.779736Z",
          "shell.execute_reply.started": "2025-03-07T00:22:53.1909Z",
          "shell.execute_reply": "2025-03-07T00:22:53.778654Z"
        },
        "id": "SmVCwx_xbKk8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V76qlz_8bKk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 2\n",
        "\n",
        "Discuta la gráfica anterior"
      ],
      "metadata": {
        "id": "fq4k3lobbKk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercico 2\n",
        "\n",
        "\n",
        "En la gráfica de EEG se observan múltiples canales representados por líneas de diferentes colores, cada una reflejando la actividad eléctrica de un electrodo colocado en el cuero cabelludo. Entre los segundos 2 y 5, se pueden notar variaciones en la amplitud de las señales en las regiones central (C3, Cz, C4), frontal central (FCz) y central posterior (CPz), lo que sugiere cambios en la activación neuronal. Se evidencia una disminución en la amplitud de ciertas frecuencias, especialmente en la banda Alpha (8-13 Hz), lo que es característico cuando una persona imagina movimientos. Además, se pueden notar pequeños picos y fluctuaciones en algunas señales, lo que podría estar asociado con la dinámica del procesamiento motor y la concentración del sujeto durante la tarea de imaginación. Conforme el tiempo avanza, la actividad tiende a estabilizarse, indicando que el cerebro regresa a un estado más neutral una vez finalizada la tarea mental.\n",
        "\n",
        "En la gráfica de EEG, el intervalo entre 2 y 5 segundos es clave, ya que en este tiempo el sujeto está imaginando mover alguno de sus brazos. En la región central del cerebro (canales C3, Cz y C4), se pueden notar cambios en las ondas cerebrales que reflejan la activación de áreas relacionadas con el movimiento. Si el sujeto imagina mover el brazo derecho, se espera mayor actividad en el lado izquierdo del cerebro (C3), mientras que si imagina mover el brazo izquierdo, la actividad aumenta en el lado derecho (C4). Durante este proceso, se observa una disminución en ciertas ondas cerebrales, lo que indica que el cerebro está \"preparándose\" para ejecutar el movimiento, aunque este solo exista en su imaginación.\n",
        "\n",
        "En las regiones frontal central y central posterior, también se perciben cambios en la actividad cerebral que muestran cómo el cerebro planifica y procesa la acción. En la zona frontal (FCz), el cerebro parece estar organizando y decidiendo el movimiento, mientras que en la parte posterior central (CPz), es posible que esté procesando la sensación del movimiento imaginado. Además, hacia el final de cada intervalo, las ondas cerebrales empiezan a estabilizarse nuevamente, lo que podría indicar que el cerebro \"finaliza\" la tarea imaginada y vuelve a su estado de reposo."
      ],
      "metadata": {
        "id": "S8sLLAOIbKk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota: Recuerde el concepto de ritmos cerebrales\n",
        "\n",
        "![montaje](https://cdn.shopify.com/s/files/1/0348/7053/files/storage.googleapis.com-486681944373284_61cb9936-f6c2-493d-8402-3426d7f5a049_1024x1024.jpg?v=1689309340)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZowDtQwhbKk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filtramos trials completos en ritmos cerebrales utilizando filtros IIR\n",
        "\n",
        "\n",
        "f_bank = np.array([[0.5,4.],[4., 8.],[8.,13.],[13.,32.],[32.,100.]])\n",
        "vwt = np.asarray([[ti, tf]]) #2.5 - 5 MI 0 - 7 trial completo\n",
        "tf_repr = TimeFrequencyRpr(sfreq = new_fs, f_bank = f_bank)\n",
        "\n",
        "Xrc = np.squeeze(tf_repr.transform(X))\n",
        "\n",
        "Xrc.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:22:53.780954Z",
          "iopub.execute_input": "2025-03-07T00:22:53.781298Z",
          "iopub.status.idle": "2025-03-07T00:23:00.845592Z",
          "shell.execute_reply.started": "2025-03-07T00:22:53.781273Z",
          "shell.execute_reply": "2025-03-07T00:23:00.844055Z"
        },
        "id": "IIawVSSTbKk9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xm0HK9lsbKk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 3\n",
        "\n",
        "Expliqué cómo se calcularon cada una de las 5 dimensiones del arreglo Xrc"
      ],
      "metadata": {
        "id": "0Y7FrXEfbKk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 3\n",
        "Expliqué cómo se calcularon cada una de las 5 dimensiones del arreglo Xrc\n",
        "\n",
        "El canal Xrc tiene 5 dimensiones aunque en el codigo solo se muestran 4 de manera explicita (n_trials, n_canales, n_muestras, n_bands). Sin embargo, hay una quinta dimensión que no se menciona directamente (n_sujetos).\n",
        "\n",
        "n_trials : Es el numero de la prueba que estamos ejecutando, cada sujeto tiene 200 pruebas realizadas\n",
        "\n",
        "n_canales: Corresponde al número de electrodos colocados en la cabeza del sujeto para captar la actividad EEG.\n",
        "\n",
        "n_muestras: Se determina por la duración del ensayo y la frecuencia de muestreo. Por ejemplo se muestrea a 256 Hz y cada ensayo dura 3 segundos, el número de muestras es: 256 * 3 = 768\n",
        "\n",
        "n_bands: Se obtiene aplicando filtros pasa-banda sobre la señal original, se divide en las bandas estandar: Delta, Theta, Alpha, Beta, Gamma\n",
        "\n",
        "n_sujetos: Se separan los datos de cada persona en el experimento."
      ],
      "metadata": {
        "id": "ZbSpKZh1bKk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ritmo = ['delta','theta','alpha','beta','gamma']\n",
        "trial = 25\n",
        "n_trials, n_canales, n_muestras, n_bands = Xrc.shape  # Simulación de datos\n",
        "\n",
        "esp = 2 #espaciado canales\n",
        "fig,ax = plt.subplots(5,1,figsize=(8,40))\n",
        "# Graficar cada canal en un subplot banda respectiva\n",
        "for b in range(f_bank.shape[0]): #bandas\n",
        "    plot_eeg(Xrc[trial,:,:,b],tv,ax=ax[b],channels=channels,title=f'EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]}')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:23:00.847079Z",
          "iopub.execute_input": "2025-03-07T00:23:00.847552Z"
        },
        "id": "IFosclbxbKk-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.widgets import Slider\n",
        "\n",
        "# Variable global para almacenar la información procesada de cada sujeto.\n",
        "# Estructura:\n",
        "# global_eeg_promedios[sbj] = { 'left': left_filtered, 'right': right_filtered, 'time': tv }\n",
        "# Donde left/right tienen forma (canales, muestras, bandas)\n",
        "global_eeg_promedios1 = {}\n",
        "\n",
        "# Lista de índices de canales de interés: canales que comienzan con \"FC\", \"C\" o \"CP\"\n",
        "canales_de_interes = [i for i, ch in enumerate(channels) if ch.startswith(('FC', 'C', 'CP'))]\n",
        "\n",
        "# Instanciar el transformador de tiempo-frecuencia usando el banco de filtros (f_bank) y la nueva frecuencia de muestreo\n",
        "tf_repr = TimeFrequencyRpr(sfreq=new_fs, f_bank=f_bank, vwt=None)\n",
        "\n",
        "# Iterar sobre los 52 sujetos\n",
        "for sbj in range(1, 10):\n",
        "    if(29 == sbj or 34 == sbj):\n",
        "        pass\n",
        "    else:\n",
        "        print(f\"Procesando sujeto {sbj}...\")\n",
        "\n",
        "        # Cargar datos: load_GIGA retorna X (EEG) y y (etiquetas: 0 para mano izquierda, 1 para mano derecha)\n",
        "        X, y = load_GIGA(sbj=sbj, **load_args)\n",
        "\n",
        "        # Filtrar para quedarse solo con los canales de interés\n",
        "        # X tiene forma (trials, canales, muestras)\n",
        "        X_filtrado = X[:, canales_de_interes, :]\n",
        "\n",
        "        # Separar ensayos según la mano\n",
        "        idx_left = (y == 0)\n",
        "        idx_right = (y == 1)\n",
        "\n",
        "        if np.sum(idx_left) == 0:\n",
        "            print(f\"Advertencia: Sujeto {sbj} no tiene ensayos para mano izquierda.\")\n",
        "            continue\n",
        "        if np.sum(idx_right) == 0:\n",
        "            print(f\"Advertencia: Sujeto {sbj} no tiene ensayos para mano derecha.\")\n",
        "            continue\n",
        "\n",
        "        # Extraer ensayos por condición\n",
        "        X_left = X_filtrado[idx_left, :, :]   # forma: (n_trials_left, canales, muestras)\n",
        "        X_right = X_filtrado[idx_right, :, :] # forma: (n_trials_right, canales, muestras)\n",
        "\n",
        "        # Aplicar filtrado en bandas para cada condición:\n",
        "        # La función transform de tf_repr devuelve una salida de forma (trials, canales, muestras, 1, bandas)\n",
        "        Xrc_left = tf_repr.transform(X_left)\n",
        "        Xrc_left = np.squeeze(Xrc_left, axis=3)   # Ahora: (trials, canales, muestras, bandas)\n",
        "        Xrc_right = tf_repr.transform(X_right)\n",
        "        Xrc_right = np.squeeze(Xrc_right, axis=3)  # (trials, canales, muestras, bandas)\n",
        "\n",
        "        # Promediar sobre los ensayos (trials) para cada condición\n",
        "        left_filtered = np.mean(Xrc_left, axis=0)   # (canales, muestras, bandas)\n",
        "        right_filtered = np.mean(Xrc_right, axis=0)   # (canales, muestras, bandas)\n",
        "\n",
        "        # Definir el vector de tiempo (suponiendo new_fs es la nueva frecuencia de muestreo)\n",
        "        ti = 0\n",
        "        tf_total = left_filtered.shape[1] / new_fs  # Asumimos misma cantidad de muestras en ambas condiciones\n",
        "        tv = np.arange(ti, tf_total, 1 / new_fs)\n",
        "\n",
        "        # Almacenar la información en la variable global para uso posterior\n",
        "        global_eeg_promedios1[sbj] = {'left': left_filtered, 'right': right_filtered, 'time': tv}\n",
        "\n",
        "        # Crear figura con 2 filas (una por condición) y N columnas (N = número de bandas, p.ej., 5)\n",
        "        n_bands = f_bank.shape[0]\n",
        "        fig, axes = plt.subplots(2, n_bands, figsize=(4*n_bands, 8), sharey=True, sharex=True)\n",
        "\n",
        "        # Si solo hay una columna, convertir axes a 2D para evitar errores\n",
        "        if n_bands == 1:\n",
        "            axes = np.expand_dims(axes, axis=1)\n",
        "\n",
        "        # Graficar para cada banda\n",
        "        for b in range(n_bands):\n",
        "            title_left = f'Izq: {f_bank[b,0]}-{f_bank[b,1]} Hz'\n",
        "            title_right = f'Der: {f_bank[b,0]}-{f_bank[b,1]} Hz'\n",
        "            # plot_eeg espera datos con forma (canales, muestras)\n",
        "            plot_eeg(left_filtered[:, :, b], tv, ax=axes[0, b],\n",
        "                     channels=[channels[i] for i in canales_de_interes],\n",
        "                     title=title_left)\n",
        "            plot_eeg(right_filtered[:, :, b], tv, ax=axes[1, b],\n",
        "                     channels=[channels[i] for i in canales_de_interes],\n",
        "                     title=title_right)\n",
        "\n",
        "        # Ajustar ventana temporal para visualizar usando slider\n",
        "        window_length = 7  # duración en segundos de la ventana visible inicialmente\n",
        "        initial_start = 0\n",
        "        initial_end = initial_start + window_length\n",
        "        for ax in axes.flatten():\n",
        "            ax.set_xlim(initial_start, initial_end)\n",
        "\n",
        "        plt.suptitle(f\"EEG Filtrado por Banda - Sujeto {sbj}\\n(Arriba: Mano Izquierda, Abajo: Mano Derecha)\")\n",
        "        plt.show()\n",
        "        plt.close(fig)\n",
        "\n",
        "        print(f\"Procesado y mostrado sujeto {sbj}\")\n",
        "\n",
        "    print(\"Procesamiento completado para todos los sujetos.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.idle": "2025-03-07T00:24:15.727793Z",
          "shell.execute_reply.started": "2025-03-07T00:23:05.747896Z",
          "shell.execute_reply": "2025-03-07T00:24:15.726546Z"
        },
        "id": "ZooKnNXHbKk-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.widgets import Slider\n",
        "\n",
        "# Variable global para almacenar la información procesada de cada sujeto.\n",
        "# Estructura:\n",
        "# global_eeg_promedios[sbj] = { 'left': left_filtered, 'right': right_filtered, 'time': tv }\n",
        "# Donde left/right tienen forma (canales, muestras, bandas)\n",
        "global_eeg_promedios = {}\n",
        "\n",
        "# Lista de índices de canales de interés\n",
        "canales_de_interes = [i for i, ch in enumerate(channels) if ch.startswith(('FC', 'C', 'CP'))]\n",
        "\n",
        "# Instanciar el transformador de tiempo-frecuencia\n",
        "tf_repr = TimeFrequencyRpr(sfreq=new_fs, f_bank=f_bank, vwt=None)\n",
        "\n",
        "# Iterar sobre un rango de sujetos\n",
        "for sbj in range(1, 52):\n",
        "    if sbj in [29, 34]:\n",
        "        pass\n",
        "    else:\n",
        "        print(f\"Procesando sujeto {sbj}...\")\n",
        "\n",
        "        # Cargar datos originales: X (trials, n_canales, n_muestras) y y (etiquetas)\n",
        "        X, y = load_GIGA(sbj=sbj, **load_args)\n",
        "\n",
        "        # En lugar de descartar los canales, creamos una copia con ceros\n",
        "        # del mismo tamaño que X\n",
        "        X_zero = np.zeros_like(X)  # Mantiene la forma (trials, n_canales, n_muestras)\n",
        "\n",
        "        # Rellenar con los datos originales solo en canales_de_interes\n",
        "        X_zero[:, canales_de_interes, :] = X[:, canales_de_interes, :]\n",
        "\n",
        "        # Separar ensayos según la mano\n",
        "        idx_left = (y == 0)\n",
        "        idx_right = (y == 1)\n",
        "\n",
        "        if np.sum(idx_left) == 0:\n",
        "            print(f\"Advertencia: Sujeto {sbj} no tiene ensayos para mano izquierda.\")\n",
        "            continue\n",
        "        if np.sum(idx_right) == 0:\n",
        "            print(f\"Advertencia: Sujeto {sbj} no tiene ensayos para mano derecha.\")\n",
        "            continue\n",
        "\n",
        "        # Extraer ensayos por condición usando X_zero (con ceros fuera de canales_de_interes)\n",
        "        X_left = X_zero[idx_left, :, :]    # (n_trials_left, n_canales, n_muestras)\n",
        "        X_right = X_zero[idx_right, :, :]  # (n_trials_right, n_canales, n_muestras)\n",
        "\n",
        "        # Aplicar filtrado en bandas\n",
        "        # tf_repr.transform devuelve (trials, canales, muestras, 1, bandas)\n",
        "        Xrc_left = tf_repr.transform(X_left)\n",
        "        Xrc_left = np.squeeze(Xrc_left, axis=3)   # => (trials, n_canales, n_muestras, n_bands)\n",
        "        Xrc_right = tf_repr.transform(X_right)\n",
        "        Xrc_right = np.squeeze(Xrc_right, axis=3) # => (trials, n_canales, n_muestras, n_bands)\n",
        "\n",
        "        # Promediar sobre los ensayos => (n_canales, n_muestras, n_bands)\n",
        "        left_filtered = np.mean(Xrc_left, axis=0)\n",
        "        right_filtered = np.mean(Xrc_right, axis=0)\n",
        "\n",
        "        # Definir el vector de tiempo\n",
        "        tf_total = left_filtered.shape[1] / new_fs\n",
        "        tv = np.arange(0, tf_total, 1 / new_fs)\n",
        "\n",
        "        # Guardar en la variable global\n",
        "        global_eeg_promedios[sbj] = {\n",
        "            'left':  left_filtered,   # (n_canales, n_muestras, n_bands)\n",
        "            'right': right_filtered,  # (n_canales, n_muestras, n_bands)\n",
        "            'time':  tv               # (n_muestras,)\n",
        "        }\n",
        "\n",
        "\n",
        "        print(f\"Procesado y mostrado sujeto {sbj}\")\n",
        "\n",
        "print(\"Procesamiento completado para todos los sujetos.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:24:15.728768Z",
          "iopub.execute_input": "2025-03-07T00:24:15.729072Z",
          "iopub.status.idle": "2025-03-07T00:29:42.793413Z",
          "shell.execute_reply.started": "2025-03-07T00:24:15.729039Z",
          "shell.execute_reply": "2025-03-07T00:29:42.792038Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7vCZiC9bKlE",
        "outputId": "3aed6afa-b653-42da-b86c-1ba3821969b3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando sujeto 1...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 1\n",
            "Procesando sujeto 2...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 2\n",
            "Procesando sujeto 3...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 3\n",
            "Procesando sujeto 4...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 4\n",
            "Procesando sujeto 5...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 5\n",
            "Procesando sujeto 6...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 6\n",
            "Procesando sujeto 7...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 7\n",
            "Procesando sujeto 8...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 8\n",
            "Procesando sujeto 9...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 9\n",
            "Procesando sujeto 10...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 10\n",
            "Procesando sujeto 11...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 11\n",
            "Procesando sujeto 12...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 12\n",
            "Procesando sujeto 13...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 13\n",
            "Procesando sujeto 14...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 14\n",
            "Procesando sujeto 15...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 15\n",
            "Procesando sujeto 16...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 16\n",
            "Procesando sujeto 17...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 17\n",
            "Procesando sujeto 18...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 18\n",
            "Procesando sujeto 19...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 19\n",
            "Procesando sujeto 20...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 20\n",
            "Procesando sujeto 21...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 21\n",
            "Procesando sujeto 22...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 22\n",
            "Procesando sujeto 23...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 23\n",
            "Procesando sujeto 24...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 24\n",
            "Procesando sujeto 25...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 25\n",
            "Procesando sujeto 26...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 26\n",
            "Procesando sujeto 27...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 27\n",
            "Procesando sujeto 28...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 28\n",
            "Procesando sujeto 30...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The subject 30 in the run 2 has no data.\n",
            "WARNING:root:The subject 30 in the run 2 has no data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 30\n",
            "Procesando sujeto 31...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 31\n",
            "Procesando sujeto 32...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 32\n",
            "Procesando sujeto 33...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 33\n",
            "Procesando sujeto 35...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 35\n",
            "Procesando sujeto 36...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 36\n",
            "Procesando sujeto 37...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 37\n",
            "Procesando sujeto 38...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 38\n",
            "Procesando sujeto 39...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 39\n",
            "Procesando sujeto 40...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 40\n",
            "Procesando sujeto 41...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 41\n",
            "Procesando sujeto 42...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 42\n",
            "Procesando sujeto 43...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 43\n",
            "Procesando sujeto 44...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 44\n",
            "Procesando sujeto 45...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 45\n",
            "Procesando sujeto 46...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 46\n",
            "Procesando sujeto 47...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 47\n",
            "Procesando sujeto 48...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 48\n",
            "Procesando sujeto 49...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 49\n",
            "Procesando sujeto 50...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 50\n",
            "Procesando sujeto 51...\n",
            "Resampling from 512.000000 to 256.000000 Hz.\n",
            "Procesado y mostrado sujeto 51\n",
            "Procesamiento completado para todos los sujetos.\n"
          ]
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización de las señales de EEG en la frecuencia"
      ],
      "metadata": {
        "id": "gIfJFETKbKlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#señal orignal\n",
        "Xwo = np.fft.rfft(X,axis=-1)\n",
        "vfreq = np.fft.rfftfreq(X.shape[2],1/new_fs)\n",
        "\n",
        "Xwo.shape\n",
        "plt.plot(vfreq,20*np.log10(np.abs(Xwo[trial])).T)\n",
        "plt.xlabel('Frecuencia [Hz]')\n",
        "plt.ylabel('Magnitud [dB]')\n",
        "plt.title('Eespectro Señal EEG original')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:29:42.794629Z",
          "iopub.execute_input": "2025-03-07T00:29:42.795071Z",
          "iopub.status.idle": "2025-03-07T00:29:43.150683Z",
          "shell.execute_reply.started": "2025-03-07T00:29:42.795025Z",
          "shell.execute_reply": "2025-03-07T00:29:43.149403Z"
        },
        "id": "81T_5560bKlF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 4\n",
        "\n",
        "Discuta la gráfica anterior"
      ],
      "metadata": {
        "id": "t7vg6QV-bKlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "punto 4\n",
        "La gráfica representa el espectro de frecuencia de una señal EEG original, mostrando la distribución de su energía en diferentes frecuencias. En el eje X se observa el rango de frecuencias desde 0 hasta aproximadamente 125 Hz, mientras que el eje Y representa la magnitud en decibeles, indicando la intensidad de la señal en cada frecuencia. Destaca un pico pronunciado en las frecuencias más bajas, alrededor de los 0-5 Hz, lo que sugiere la presencia de ondas delta o posibles artefactos fisiológicos, como movimientos oculares o actividad de fondo. A medida que la frecuencia aumenta, la magnitud de la señal decrece rápidamente, lo que es característico de las señales EEG, ya que la mayor parte de la actividad cerebral se concentra en frecuencias bajas.\n",
        "\n",
        "A partir de los 30 Hz, la señal muestra un comportamiento más irregular y disperso, lo que podría indicar la presencia de ruido electromagnético o la actividad de bandas como beta y gamma, asociadas con procesos cognitivos y motores. La distribución observada refuerza la idea de que las señales EEG tienen un espectro dominado por bajas frecuencias, con una actividad progresivamente más débil a medida que la frecuencia aumenta."
      ],
      "metadata": {
        "id": "YVX6rSX0bKlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#espectro señales filtradas\n",
        "Xwb = np.fft.rfft(Xrc,axis=2)\n",
        "\n",
        "Xwb.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:29:43.151593Z",
          "iopub.execute_input": "2025-03-07T00:29:43.152102Z",
          "iopub.status.idle": "2025-03-07T00:29:43.798606Z",
          "shell.execute_reply.started": "2025-03-07T00:29:43.152009Z",
          "shell.execute_reply": "2025-03-07T00:29:43.79731Z"
        },
        "id": "VGpbrvN2bKlO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#espectro señales filtradas por bandas - ritmos cerebrales\n",
        "\n",
        "fig,ax = plt.subplots(5,1,figsize=(8,40))\n",
        "# Graficar cada canal en un subplot banda respectiva\n",
        "for b in range(f_bank.shape[0]): #bandas\n",
        "    ax[b].plot(vfreq,20*np.log10(np.abs(Xwb[trial,:,:,b])).T)\n",
        "    ax[b].set_xlabel('Frecuencia [Hz]')\n",
        "    ax[b].set_ylabel('Magnitud [dB]')\n",
        "    ax[b].set_title(f'Esepctro EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]}')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:29:43.803314Z",
          "iopub.execute_input": "2025-03-07T00:29:43.803592Z",
          "iopub.status.idle": "2025-03-07T00:29:44.967642Z",
          "shell.execute_reply.started": "2025-03-07T00:29:43.803573Z",
          "shell.execute_reply": "2025-03-07T00:29:44.966269Z"
        },
        "id": "ZFb2aDyQbKlO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Iterar sobre cada sujeto almacenado en la variable global\n",
        "for sbj in sorted(global_eeg_promedios.keys()):\n",
        "\n",
        "    if sbj == 29 or sbj == 34:\n",
        "        continue\n",
        "    else:\n",
        "        data = global_eeg_promedios[sbj]\n",
        "        left = data['left']    # forma: (canales, muestras, bandas)\n",
        "        right = data['right']  # forma: (canales, muestras, bandas)\n",
        "        tv = data['time']\n",
        "\n",
        "        n_samples = left.shape[1]\n",
        "        fs = new_fs  # frecuencia de muestreo\n",
        "        # Generar vector de frecuencias a partir de la FFT\n",
        "        freqs = np.fft.fftfreq(n_samples, d=1/fs)\n",
        "        pos_idx = freqs >= 0  # consideramos solo las frecuencias positivas\n",
        "        pos_freqs = freqs[pos_idx]\n",
        "\n",
        "        n_bands = left.shape[2]  # número de bandas (por ej. 5)\n",
        "\n",
        "        # Arrays para almacenar la magnitud en dB para cada banda\n",
        "        fft_left_db = np.zeros((n_bands, np.sum(pos_idx)))\n",
        "        fft_right_db = np.zeros((n_bands, np.sum(pos_idx)))\n",
        "\n",
        "        # Crear figura con 2 filas (izquierda y derecha) y n_bands columnas (una por banda)\n",
        "        fig, axes = plt.subplots(2, n_bands, figsize=(4*n_bands, 8), sharey=True)\n",
        "\n",
        "        for b in range(n_bands):\n",
        "            # Promediar la señal a través de los canales para cada banda\n",
        "            left_avg = np.mean(left[:, :, b], axis=0)   # vector de longitud = n_samples\n",
        "            right_avg = np.mean(right[:, :, b], axis=0)\n",
        "\n",
        "            # Calcular la FFT y obtener la magnitud\n",
        "            left_fft = np.fft.fft(left_avg)\n",
        "            right_fft = np.fft.fft(right_avg)\n",
        "            # Magnitud de la FFT (solo para frecuencias positivas)\n",
        "            left_mag = np.abs(left_fft)[pos_idx]\n",
        "            right_mag = np.abs(right_fft)[pos_idx]\n",
        "            # Convertir a dB (se suma un pequeño epsilon para evitar log(0))\n",
        "            eps = 1e-12\n",
        "            left_db = 20 * np.log10(left_mag + eps)\n",
        "            right_db = 20 * np.log10(right_mag + eps)\n",
        "\n",
        "            # Almacenar la transformación en los arrays\n",
        "            fft_left_db[b, :] = left_db\n",
        "            fft_right_db[b, :] = right_db\n",
        "\n",
        "            # Graficar en el subplot correspondiente\n",
        "            axes[0, b].plot(pos_freqs, left_db, color='blue')\n",
        "            axes[0, b].set_title(f'Mano Izquierda\\n{f_bank[b,0]}-{f_bank[b,1]} Hz')\n",
        "            axes[0, b].set_xlabel('Frecuencia (Hz)')\n",
        "            axes[0, b].set_ylabel('Amplitud (dB)')\n",
        "\n",
        "            axes[1, b].plot(pos_freqs, right_db, color='red')\n",
        "            axes[1, b].set_title(f'Mano Derecha\\n{f_bank[b,0]}-{f_bank[b,1]} Hz')\n",
        "            axes[1, b].set_xlabel('Frecuencia (Hz)')\n",
        "            axes[1, b].set_ylabel('Amplitud (dB)')\n",
        "\n",
        "        plt.suptitle(f'Espectro de EEG - Sujeto {sbj} (Promediado sobre canales)')\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "        plt.show()\n",
        "\n",
        "        # Guardar la información de la transformación en la variable global\n",
        "        # Se agrega un nuevo campo 'fft' que contiene los espectros en dB y el vector de frecuencias\n",
        "        global_eeg_promedios[sbj]['fft'] = {\n",
        "            'left': fft_left_db,\n",
        "            'right': fft_right_db,\n",
        "            'freqs': pos_freqs\n",
        "        }\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:29:44.971912Z",
          "iopub.execute_input": "2025-03-07T00:29:44.972235Z",
          "iopub.status.idle": "2025-03-07T00:31:02.87718Z"
        },
        "id": "tb9kYWLgbKlO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 5\n",
        "\n",
        "Discuta las gráficas"
      ],
      "metadata": {
        "id": "y9NLOdOvbKlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 5\n",
        "Discuta las gráficas\n",
        "\n",
        "Solucion\n",
        "Las graficas a analizar corresponden a las 5 ondas principales que estamos utilizando en nuestro estudio, es decir las ondas Gamma, Beta, Alpha,Theta, Delta asi que vamos a analizar cada una por separado\n",
        "\n",
        "Empezaremos por el ritmo Delta las cuales estan relacionadas con el sueño profundo y la relajacion elevada, estas ondas se encuentran en un rango de frecuencias de 0.5 - 4.0 Hz, en este rango de frecuencias podemos observar los mayores picos de la señal de todas las ondas, sin embargo su oscilacion es pobre y decaen rapidamente, lo que nos puede indicar dos cosas: existe la posibilidad de que sea un pico generado por un ruido leve como un parpadeo o puede que representen la transicion entre un estado de relajacion a un estado de concentracion.\n",
        "\n",
        "Despues tenemos las ondas Theta las cuales estan relacionadas con procesos de memoria, estados meditativos y estados de relajacion, esta banda de frecuencias presenta un comportamiento similar a las ondas Delta, lo que aumenta la probabilidad de que sea una transicion entre un estado de relajacion a un estado de concentracion el que estamos viendo\n",
        "\n",
        "Por ultimo tenemos a los ritmos Beta y Gamma, estos son los rangos de frecuencia en los que mas actividad vemos, estas señales estan relacionadas a tareas cognitivas avanzadas, ya que se ha propuesto que la sincronización theta-gamma juega un rol en el procesamiento de información en la corteza y el hipocampo.\n",
        "\n",
        "Por lo anterior podemos concluir que estas señales estan representando el paso de un estado de relajacion a un estado imaginativo"
      ],
      "metadata": {
        "id": "9DmdmjzVbKlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización de espectrogramas\n",
        "\n",
        "Consultar Short Time Fourier Transform\n",
        "\n"
      ],
      "metadata": {
        "id": "QhWsUzTGbKlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\n",
        "from scipy.signal import stft #\n",
        "nperseg = 0.5*new_fs#longitud ventas en muestras\n",
        "vfs,t,Xstft = stft(X,fs=new_fs,nperseg=nperseg,axis=2)\n",
        "Xstft = 20*np.log10(abs(Xstft))\n",
        "\n",
        "#graficar stft para un trial y un canal\n",
        "trail = 0\n",
        "chi = channels.index('C4')\n",
        "\n",
        "fig, ax = plt.subplots(2, 1,figsize=(10,6))\n",
        "\n",
        "ax[1].plot(tv,X[trail,chi,:])\n",
        "ax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\n",
        "im = ax[0].pcolormesh(t, vfs, Xstft[trail,chi])\n",
        "fig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\n",
        "plt.gca()\n",
        "plt.xlabel('t [seg]')\n",
        "plt.ylabel('f [Hz]')\n",
        "ax[0].set_title(f'Esepctrograma EEG Original -- Ch = {channels[chi]}')\n",
        "print(Xstft.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:02.881325Z",
          "iopub.execute_input": "2025-03-07T00:31:02.881614Z",
          "iopub.status.idle": "2025-03-07T00:31:04.031979Z"
        },
        "id": "chFGGWstbKlP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\n",
        "b = 2\n",
        "vfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\n",
        "Xstftb = 20*np.log10(abs(Xstftb))\n",
        "\n",
        "print(Xstftb.shape)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(2, 1,figsize=(10,6))\n",
        "ax[1].plot(tv,Xrc[trail,chi,:,b])\n",
        "ax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\n",
        "im = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\n",
        "fig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\n",
        "plt.gca()\n",
        "plt.xlabel('t [seg]')\n",
        "plt.ylabel('f [Hz]')\n",
        "ax[0].set_title(f'Esepctrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:04.035544Z",
          "iopub.execute_input": "2025-03-07T00:31:04.035945Z",
          "iopub.status.idle": "2025-03-07T00:31:09.230149Z"
        },
        "id": "1VMn7Z5tbKlP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 6\n",
        "\n",
        "Presente las gráficas de stft para distintos canales en los 5 ritmos cerebrales y discuta."
      ],
      "metadata": {
        "id": "FwhXN48GbKlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import stft\n",
        "\n",
        "# Seleccionar un único sujeto (excluyendo 29 y 34)\n",
        "all_subjects = sorted(global_eeg_promedios1.keys())\n",
        "selected_subject = [sbj for sbj in all_subjects if sbj not in [29, 34]][0]\n",
        "print(\"Sujeto seleccionado:\", selected_subject)\n",
        "\n",
        "data = global_eeg_promedios1[selected_subject]\n",
        "# Usamos la condición \"mano izquierda\"\n",
        "# left_filtered tiene forma: (n_canales, n_muestras, n_bands) – se asume n_bands = 5\n",
        "left_data = data['left']\n",
        "tv = data['time']\n",
        "fs = new_fs\n",
        "\n",
        "# Definir los 5 canales deseados para mostrar\n",
        "desired_channels = [\"C3\", \"Cz\", \"C4\", \"FC3\", \"FC4\"]\n",
        "# Obtener los nombres de los canales filtrados (usando la lista global 'channels' y 'canales_de_interes')\n",
        "filtered_channels = [channels[i] for i in canales_de_interes]\n",
        "\n",
        "# Obtener los índices de los canales deseados dentro de los canales filtrados\n",
        "desired_indices = []\n",
        "for ch in desired_channels:\n",
        "    if ch in filtered_channels:\n",
        "        desired_indices.append(filtered_channels.index(ch))\n",
        "    else:\n",
        "        print(f\"Advertencia: El canal {ch} no se encuentra entre los canales filtrados.\")\n",
        "\n",
        "n_channels_plot = len(desired_indices)\n",
        "n_bands = left_data.shape[2]  # Se espera 5 bandas\n",
        "\n",
        "# Parámetro para STFT: ventana de 0.5 segundos en muestras\n",
        "nperseg = int(0.5 * new_fs)\n",
        "\n",
        "# Vamos a crear una figura con 10 filas (2 por cada banda) y n_channels_plot columnas.\n",
        "# Fila 2*i     : STFT para la banda i\n",
        "# Fila 2*i + 1 : Señal en dominio del tiempo para la banda i\n",
        "fig, axes = plt.subplots(2 * n_bands, n_channels_plot, figsize=(4 * n_channels_plot, 2 * 2 * n_bands), sharex=True)\n",
        "\n",
        "# Asegurarse de que axes es 2D (en caso de n_channels_plot == 1)\n",
        "if n_channels_plot == 1:\n",
        "    axes = np.array([[axes[i]] for i in range(2*n_bands)])\n",
        "\n",
        "# Iterar sobre cada banda (índices 0 a 4)\n",
        "for band in range(n_bands):\n",
        "    # Para cada canal deseado\n",
        "    for idx, col in enumerate(desired_indices):\n",
        "        # Extraer la señal del canal 'col' para la banda actual\n",
        "        signal_band = left_data[col, :, band]  # vector de longitud n_samples\n",
        "\n",
        "        # Calcular la STFT de la señal\n",
        "        f_vec, t_vec, Zxx = stft(signal_band, fs=fs, nperseg=nperseg)\n",
        "        eps = 1e-12\n",
        "        Zxx_db = 20 * np.log10(np.abs(Zxx) + eps)\n",
        "\n",
        "        # Calcular bordes para pcolormesh (necesarios para shading='flat')\n",
        "        if len(t_vec) > 1:\n",
        "            dt = t_vec[1] - t_vec[0]\n",
        "        else:\n",
        "            dt = 0.1\n",
        "        t_edges = np.concatenate((t_vec - dt/2, [t_vec[-1] + dt/2]))\n",
        "\n",
        "        if len(f_vec) > 1:\n",
        "            df = f_vec[1] - f_vec[0]\n",
        "        else:\n",
        "            df = 1.0\n",
        "        f_edges = np.concatenate((f_vec - df/2, [f_vec[-1] + df/2]))\n",
        "\n",
        "        # Ubicar la gráfica de la STFT en la fila 2*band, columna idx\n",
        "        ax_stft = axes[2*band, idx]\n",
        "        im = ax_stft.pcolormesh(t_edges, f_edges, Zxx_db, shading='flat', cmap='viridis')\n",
        "        fig.colorbar(im, ax=ax_stft, orientation='horizontal', pad=0.2)\n",
        "        ax_stft.set_title(f\"{filtered_channels[col]}\\n{f_bank[band,0]}-{f_bank[band,1]} Hz\")\n",
        "        ax_stft.set_xlabel(\"Tiempo [s]\")\n",
        "        ax_stft.set_ylabel(\"Frecuencia [Hz]\")\n",
        "\n",
        "        # Graficar la señal en el dominio del tiempo en la fila 2*band+1\n",
        "        ax_time = axes[2*band + 1, idx]\n",
        "        ax_time.plot(tv, signal_band)\n",
        "        ax_time.set_title(f\"Señal {filtered_channels[col]}\")\n",
        "        ax_time.set_xlabel(\"Tiempo [s]\")\n",
        "        ax_time.set_ylabel(\"Amplitud [$\\mu$V]\")\n",
        "\n",
        "fig.suptitle(f\"STFT en Bloques para las 5 Bandas - Sujeto {selected_subject} (Mano Izquierda)\", fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:09.233981Z",
          "iopub.execute_input": "2025-03-07T00:31:09.234274Z",
          "iopub.status.idle": "2025-03-07T00:31:19.940048Z"
        },
        "id": "koHxmzw7bKlQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización de señales EEG sobre montaje 10-20"
      ],
      "metadata": {
        "id": "qkNQhRWObKlQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F7kp1xZmbKlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "\n",
        "# Cargar el montaje estándar\n",
        "easycap_montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
        "\n",
        "\n",
        "# Crear un montaje personalizado con los electrodos seleccionados\n",
        "custom_pos = {ch: easycap_montage.get_positions()[\"ch_pos\"][ch] for ch in channels}\n",
        "custom_montage = mne.channels.make_dig_montage(ch_pos=custom_pos, coord_frame=\"head\")\n",
        "\n",
        "# Mostrar el montaje personalizado\n",
        "custom_montage.plot(show_names=True)\n",
        "fig = custom_montage.plot(kind=\"3d\", show_names=True, show=False)\n",
        "fig.gca().view_init(azim=70, elev=15)  # Ajustar la vista 3D"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:19.940903Z",
          "iopub.execute_input": "2025-03-07T00:31:19.941238Z",
          "iopub.status.idle": "2025-03-07T00:31:20.393237Z"
        },
        "id": "j5e-4oXtbKlR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git"
      ],
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:20.394002Z",
          "iopub.execute_input": "2025-03-07T00:31:20.394274Z",
          "iopub.status.idle": "2025-03-07T00:31:25.86201Z"
        },
        "id": "1VsGV4E_bKlR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topomaps"
      ],
      "metadata": {
        "id": "QzvTYesCbKlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from gcpds.visualizations.topoplots import topoplot\n",
        "import mne\n",
        "\n",
        "# Cargar el montaje estándar\n",
        "easycap_montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
        "\n",
        "\n",
        "# Crear un montaje personalizado con los electrodos seleccionados\n",
        "custom_pos = {ch: easycap_montage.get_positions()[\"ch_pos\"][ch] for ch in channels}\n",
        "custom_montage = mne.channels.make_dig_montage(ch_pos=custom_pos, coord_frame=\"head\")\n",
        "\n",
        "# Mostrar el montaje personalizado\n",
        "custom_montage.plot(show_names=True)\n",
        "fig = custom_montage.plot(kind=\"3d\", show_names=True, show=False)\n",
        "fig.gca().view_init(azim=70, elev=15)  # Ajustar la vista 3D\n",
        "\n",
        "trial = 150\n",
        "vec_topo_o = abs(X[trial,:]).mean(axis=-1)\n",
        "vec_topo_b = abs(Xrc[trial,:,:,:]).mean(axis=1)\n",
        "\n",
        "\n",
        "fig,ax = plt.subplots(1,6,figsize=(20,10))\n",
        "topoplot(vec_topo_o, channels, contours=3, cmap='Reds', names=channels, sensors=False,ax=ax[0],show=False,vlim=(min(vec_topo_o), max(vec_topo_o)))\n",
        "\n",
        "for b in range(f_bank.shape[0]):\n",
        "    vec_ = vec_topo_b[:,b]\n",
        "    topoplot(vec_, channels, contours=3, cmap='Reds', names=channels, sensors=False,ax=ax[b+1],show=False,vlim=(min(vec_), max(vec_)))\n",
        "    ax[b+1].set_title(ritmo[b])\n",
        "\n",
        "ax[0].set_title(f'EEG-suj={sbj}-trial={trial}')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:25.86302Z",
          "iopub.execute_input": "2025-03-07T00:31:25.863275Z",
          "iopub.status.idle": "2025-03-07T00:31:27.830271Z"
        },
        "id": "fMvxTTqbbKlS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 7\n",
        "\n",
        "Discuta"
      ],
      "metadata": {
        "id": "93wbMdMrbKlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La banda alpha está asociada con la relajación y la tranquilidad mental. Si en nuestras gráficas vemos mucha actividad en la parte trasera de la cabeza, eso indica que el cerebro está en un estado de calma, sin procesar demasiada información externa. Sin embargo, si el experimento consiste en imaginar un movimiento, lo normal es que esta actividad disminuya en la parte superior del cerebro, señal de que la persona está concentrada en la tarea. En otras palabras, cuando alguien se enfoca en mover algo con la mente, su cerebro sale de ese estado de reposo y comienza a activarse.\n",
        "\n",
        "Por su parte, la banda beta está relacionada con la concentración y el pensamiento activo. Si en la gráfica aparece mucha actividad en la parte frontal y superior de la cabeza, significa que el cerebro está trabajando intensamente, tal vez planeando un movimiento o procesando información. Si esta actividad beta es más fuerte en los lados superiores, es una señal de que la persona está pensando en mover su cuerpo, aunque no lo haga físicamente. Además, si vemos que la banda alpha baja en esas zonas mientras la beta sube, podemos decir con más certeza que la persona realmente está enfocada en imaginar una acción."
      ],
      "metadata": {
        "id": "447__rSAbKlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common Spatial Patterns"
      ],
      "metadata": {
        "id": "rwNGW2xCbKlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "from mne.decoding import CSP\n",
        "\n",
        "# Instancia del objeto CSP\n",
        "n_components = 2\n",
        "csp = CSP(n_components=n_components, log= True, transform_into='average_power')\n",
        "# Ajuste y transformación de los datos\n",
        "csp_data = csp.fit_transform(X.astype(np.float64), y)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:27.831032Z",
          "iopub.execute_input": "2025-03-07T00:31:27.831296Z",
          "iopub.status.idle": "2025-03-07T00:31:30.600918Z"
        },
        "id": "b_yRPDWybKlS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CSP Transformado Shape:\", csp_data.shape)\n",
        "plt.scatter(csp_data[:,0],csp_data[:,1],c=y)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:30.601604Z",
          "iopub.execute_input": "2025-03-07T00:31:30.601777Z",
          "iopub.status.idle": "2025-03-07T00:31:30.725746Z"
        },
        "id": "FRYqXCjEbKlT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#EEG original\n",
        "fig,ax = plt.subplots(1,n_components,figsize=(5,5))\n",
        "for cc in range(n_components):\n",
        "    vec_ = np.abs(csp.filters_[cc])\n",
        "    topoplot(vec_, channels, contours=3, cmap='Reds', names=channels, sensors=False,ax=ax[cc],show=False,vlim=(min(vec_), max(vec_)))\n",
        "    ax[cc].set_title(f'CSP {cc+1}')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:30.726636Z",
          "iopub.execute_input": "2025-03-07T00:31:30.726913Z",
          "iopub.status.idle": "2025-03-07T00:31:31.184539Z"
        },
        "id": "wEJcXj_4bKlT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#lectura de datos\n",
        "sbj = 2\n",
        "X, y = load_GIGA(sbj=sbj, **load_args)\n",
        "\n",
        "f_bank = np.array([[0.5,4.],[4., 8.],[8.,13.],[13.,32.],[32.,100.]])\n",
        "vwt = np.array([[0.25, 1.75],[1.5,3],[2.75,4.25],[4,5.5],[5.25,6.75]]) #2.5 - 5 MI 0 - 7 trial completo\n",
        "tf_repr = TimeFrequencyRpr(sfreq = new_fs, f_bank = f_bank,vwt=vwt)\n",
        "X_ = np.squeeze(tf_repr.transform(X))\n",
        "X_.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:31.185339Z",
          "iopub.execute_input": "2025-03-07T00:31:31.185601Z",
          "iopub.status.idle": "2025-03-07T00:31:40.577987Z"
        },
        "id": "z37GoyJybKlT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# csp por ventanas y ritmos\n",
        "# Definir las dimensiones del arreglo\n",
        "ritmos_ = f_bank.shape[0]\n",
        "ventanas_ = vwt.shape[0]\n",
        "n_comp = 2\n",
        "# Inicializar el arreglo vacío con listas anidadas\n",
        "csp_M = [[None for _ in range(ventanas_)] for _ in range(ritmos_)]\n",
        "csp_filters_ = np.zeros((ritmos_,ventanas_,X_.shape[1],X_.shape[1])) #ritmos ventanas Ch\n",
        "Xcsp_ = np.zeros((X_.shape[0],n_comp,ritmos_,ventanas_))\n",
        "\n",
        "for i in range(ritmos_):\n",
        "    for j in range(ventanas_):\n",
        "        print(f'CSP ritmo {f_bank[i]} -- ventana {vwt[j]}...')\n",
        "        csp_M[i][j] =  CSP(n_components=n_comp, log= True, transform_into='average_power')\n",
        "        Xcsp_[:,:,i,j] = csp.fit_transform(X_[:,:,:,j,i].astype(np.float64), y)\n",
        "        csp_filters_[i,j,:] = np.abs(csp.filters_)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:40.578722Z",
          "iopub.execute_input": "2025-03-07T00:31:40.578961Z",
          "iopub.status.idle": "2025-03-07T00:31:52.432682Z"
        },
        "id": "-ZAUF4QmbKlU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# graficar topomaps\n",
        "fig, ax = plt.subplots(ritmos_,ventanas_,figsize=(12,12))\n",
        "\n",
        "for i in range(ritmos_):\n",
        "    for j in range(ventanas_):\n",
        "        vec_ = csp_filters_[i,j,0]\n",
        "        vec_ = vec_/max(vec_)\n",
        "        topoplot(vec_, channels, contours=3, cmap='Reds', names=None, sensors=False,ax=ax[i,j],show=False,vlim=(min(vec_), max(vec_)))\n",
        "    ax[i,0].set_ylabel(ritmo[i],fontsize=20)\n",
        "for j in range(ventanas_):\n",
        "     ax[0,j].set_title(f'{vwt[j,0]}--{vwt[j,1]} [s]',fontsize=15)\n",
        "\n",
        "plt.subplots_adjust(hspace=-0.025,wspace=-0.025)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:52.433199Z",
          "iopub.execute_input": "2025-03-07T00:31:52.433354Z",
          "iopub.status.idle": "2025-03-07T00:31:54.990254Z"
        },
        "id": "zYma87wCbKlU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar topomaps\n",
        "fig, ax = plt.subplots(ritmos_, ventanas_, figsize=(12, 12))\n",
        "\n",
        "for i in range(ritmos_):\n",
        "    for j in range(ventanas_):\n",
        "        vec_ = csp_filters_[i, j, 0]\n",
        "        vec_ = vec_ / max(vec_)  # Normalizar el vector\n",
        "        topoplot(vec_, channels, contours=3, cmap='Reds', names=None, sensors=False,\n",
        "                 ax=ax[i, j], show=False, vlim=(min(vec_), max(vec_)))\n",
        "    ax[i, 0].set_ylabel(ritmo[i], fontsize=20)\n",
        "\n",
        "for j in range(ventanas_):\n",
        "    ax[0, j].set_title(f'{vwt[j, 0]}--{vwt[j, 1]} [s]', fontsize=15)\n",
        "\n",
        "plt.subplots_adjust(hspace=-0.025, wspace=-0.025)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:54.991137Z",
          "iopub.execute_input": "2025-03-07T00:31:54.991425Z",
          "iopub.status.idle": "2025-03-07T00:31:58.040554Z"
        },
        "id": "aycr-9GsbKlU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#scatters\n",
        "fig, ax = plt.subplots(ritmos_,ventanas_,figsize=(12,12))\n",
        "\n",
        "for i in range(ritmos_):\n",
        "    for j in range(ventanas_):\n",
        "        ax[i,j].scatter(Xcsp_[:,0,i,j],Xcsp_[:,1,i,j],c=y)\n",
        "        ax[i,j].set_xticks([])\n",
        "        ax[i,j].set_yticks([])\n",
        "    ax[i,0].set_ylabel(ritmo[i],fontsize=20)\n",
        "for j in range(ventanas_):\n",
        "     ax[0,j].set_title(f'{vwt[j,0]}--{vwt[j,1]} [s]',fontsize=15)\n",
        "\n",
        "plt.subplots_adjust(hspace=0.1,wspace=0.1)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:31:58.041387Z",
          "iopub.execute_input": "2025-03-07T00:31:58.041655Z",
          "iopub.status.idle": "2025-03-07T00:31:58.87929Z"
        },
        "id": "jzSfut8rbKlU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gcpds.visualizations.topoplots import topoplot\n",
        "\n",
        "# Índices de banda en el 3er eje\n",
        "BAND_ALPHA = 2\n",
        "BAND_BETA  = 3\n",
        "\n",
        "# Ventanas de tiempo (cada columna)\n",
        "time_windows = [\n",
        "    (0.25, 1.75),\n",
        "    (1.5,  3.0),\n",
        "    (2.75, 4.25),\n",
        "    (4.0,  5.5),\n",
        "    (5.25, 6.75),\n",
        "]\n",
        "\n",
        "# Nombre de filas (row_labels):\n",
        "row_labels = [\"alpha-left\", \"beta-left\", \"alpha-right\", \"beta-right\"]\n",
        "\n",
        "# Recorremos los sujetos de la variable global\n",
        "for sbj in sorted(global_eeg_promedios.keys()):\n",
        "    data = global_eeg_promedios[sbj]\n",
        "\n",
        "    # Extraer las señales para mano izquierda y derecha\n",
        "    left_data  = data['left']   # (n_canales, n_muestras, n_bands)\n",
        "    right_data = data['right']  # (n_canales, n_muestras, n_bands)\n",
        "    tv         = data['time']   # (n_muestras,)\n",
        "\n",
        "    # Crear la figura con 4 filas (alpha-left, beta-left, alpha-right, beta-right)\n",
        "    # y 5 columnas (ventanas)\n",
        "    fig, axes = plt.subplots(4, 5, figsize=(14, 10), sharex=True, sharey=True)\n",
        "\n",
        "    # Bucle sobre las 5 columnas\n",
        "    for col, (start_t, end_t) in enumerate(time_windows):\n",
        "        # ÍNDICES de muestras en la ventana [start_t, end_t)\n",
        "        idx_time = np.where((tv >= start_t) & (tv < end_t))[0]\n",
        "\n",
        "        # Si no hay muestras en esa ventana, se deja la columna en blanco\n",
        "        if len(idx_time) == 0:\n",
        "            for row in range(4):\n",
        "                axes[row, col].set_title(f\"{start_t}-{end_t} s\\n(No data)\")\n",
        "                axes[row, col].axis(\"off\")\n",
        "            continue\n",
        "\n",
        "        # Calcular la magnitud promedio en la ventana => (n_canales, n_bands)\n",
        "        left_vec  = np.abs(left_data[:, idx_time, :]).mean(axis=1)\n",
        "        right_vec = np.abs(right_data[:, idx_time, :]).mean(axis=1)\n",
        "\n",
        "        # Extraer alpha y beta para cada mano\n",
        "        alpha_left  = left_vec[:, BAND_ALPHA]\n",
        "        beta_left   = left_vec[:, BAND_BETA]\n",
        "        alpha_right = right_vec[:, BAND_ALPHA]\n",
        "        beta_right  = right_vec[:, BAND_BETA]\n",
        "\n",
        "        # -------------- Fila 0: alpha-left --------------\n",
        "        vmin, vmax = alpha_left.min(), alpha_left.max()\n",
        "        topoplot(alpha_left, channels,\n",
        "                 ax=axes[0, col],\n",
        "                 show=False,\n",
        "                 sensors=False,\n",
        "                 cmap='viridis',  # alpha en viridis\n",
        "                 vlim=(vmin, vmax))\n",
        "        # Etiqueta\n",
        "        axes[0, col].set_title(f\"{start_t}-{end_t} s\")\n",
        "\n",
        "        # -------------- Fila 1: beta-left --------------\n",
        "        vmin, vmax = beta_left.min(), beta_left.max()\n",
        "        topoplot(beta_left, channels,\n",
        "                 ax=axes[1, col],\n",
        "                 show=False,\n",
        "                 sensors=False,\n",
        "                 cmap='Reds',  # beta en Reds\n",
        "                 vlim=(vmin, vmax))\n",
        "\n",
        "        # -------------- Fila 2: alpha-right --------------\n",
        "        vmin, vmax = alpha_right.min(), alpha_right.max()\n",
        "        topoplot(alpha_right, channels,\n",
        "                 ax=axes[2, col],\n",
        "                 show=False,\n",
        "                 sensors=False,\n",
        "                 cmap='viridis',\n",
        "                 vlim=(vmin, vmax))\n",
        "\n",
        "        # -------------- Fila 3: beta-right --------------\n",
        "        vmin, vmax = beta_right.min(), beta_right.max()\n",
        "        topoplot(beta_right, channels,\n",
        "                 ax=axes[3, col],\n",
        "                 show=False,\n",
        "                 sensors=False,\n",
        "                 cmap='Reds',\n",
        "                 vlim=(vmin, vmax))\n",
        "\n",
        "    # Etiquetas de filas\n",
        "    for row in range(4):\n",
        "        axes[row, 0].set_ylabel(row_labels[row], fontsize=12)\n",
        "\n",
        "    fig.suptitle(f\"Sujeto {sbj} - Alpha/Beta en 5 ventanas\\n(Arriba=Izquierda, Abajo=Derecha)\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T01:07:25.191778Z",
          "iopub.execute_input": "2025-03-07T01:07:25.192248Z",
          "iopub.status.idle": "2025-03-07T01:10:25.839506Z",
          "shell.execute_reply.started": "2025-03-07T01:07:25.192218Z",
          "shell.execute_reply": "2025-03-07T01:10:25.838323Z"
        },
        "id": "KvW44kcibKlV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# calculamos las matrices de coectividades (correlación)\n",
        "\n",
        "N = X.shape[0]\n",
        "connectivities_v = np.array([np.corrcoef(X[i]) for i in range(N)])\n",
        "\n",
        "print(connectivities_v.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:49:13.67652Z",
          "iopub.status.idle": "2025-03-07T00:49:13.67682Z",
          "shell.execute_reply": "2025-03-07T00:49:13.676667Z"
        },
        "id": "AFfqlQBnbKlV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from gcpds.visualizations.connectivities import CircosConnectivity\n",
        "\n",
        "N = len(channels)  # channels\n",
        "\n",
        "areas = {\n",
        "    'Frontal': ['Fpz', 'AFz', 'Fz', 'FCz'],\n",
        "    'Frontal Right': ['Fp2','AF4','AF8','F2','F4','F6','F8',],\n",
        "    'Central Right': ['FC2','FC4','FC6','FT8','C2','C4','C6','T8','CP2','CP4','CP6','TP8',],\n",
        "    'Posterior Right': ['P2','P4','P6','P8','P10','PO4','PO8','O2',],\n",
        "    'Central': ['Cz'],\n",
        "    'Posterior': ['CPz','Pz', 'Cz','POz','Oz','Iz',],\n",
        "    'Posterior Left': ['P1','P3','P5','P7','P9','PO3','PO7','O1',],\n",
        "    'Central Left': ['FC1','FC3','FC5','FT7','C1','C3','C5','T7','CP1','CP3','CP5','TP7',],\n",
        "    'Frontal Left': ['Fp1','AF3','AF7','F1','F3','F5','F7',],\n",
        "}\n",
        "\n",
        "\n",
        "conn = CircosConnectivity(\n",
        "    connectivities_v[0,:,:], channels, areas=areas, threshold=0.7,\n",
        "\n",
        "    # cmaps and themes\n",
        "    areas_cmap='Set3',\n",
        "    arcs_cmap='Wistia',\n",
        "    hemisphere_color='lightgray',\n",
        "    channel_color='#f8f9fa',\n",
        "    min_alpha=0,\n",
        "\n",
        "\n",
        "    # Texts\n",
        "    width={'hemispheres':35, 'areas':100, 'channels':60},\n",
        "    text={'hemispheres':40, 'areas':20,  'channels':40},\n",
        "    separation={'hemispheres':10, 'areas':-30, 'channels':5},\n",
        "    labelposition={'hemispheres':60, 'areas':0, 'channels':-10},\n",
        "    size=10,\n",
        "    labelsize=15,\n",
        "\n",
        "\n",
        "    # Shapes\n",
        "    show_emisphere=True,\n",
        "    arcs_separation=30,\n",
        "    connection_width=0.1,\n",
        "    small_separation=5,\n",
        "    big_separation=10,\n",
        "    offset=0,\n",
        ")\n",
        "\n",
        "conn.figure;\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:37:41.514434Z",
          "iopub.execute_input": "2025-03-07T00:37:41.514641Z",
          "iopub.status.idle": "2025-03-07T00:37:44.744945Z"
        },
        "id": "HIgYgMqObKlV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Topoplots"
      ],
      "metadata": {
        "id": "7W8x2_eBbKlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# promediemos por canales\n",
        "\n",
        "connecitivities_mean = np.mean(connectivities_v[0],axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-07T00:37:44.745943Z",
          "iopub.execute_input": "2025-03-07T00:37:44.7462Z",
          "iopub.status.idle": "2025-03-07T00:37:44.751061Z"
        },
        "id": "lhNaCWXVbKlW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graficamos las bandas de frecuencia usando fourier para el calculo"
      ],
      "metadata": {
        "id": "M2D6nQ6RbKlX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "BRLjfGmbbKlY"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}